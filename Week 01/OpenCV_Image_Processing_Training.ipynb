{"cells":[{"cell_type":"markdown","id":"41fab163","metadata":{"id":"41fab163"},"source":["\n","# OpenCV for Image Processing â€“ A Practical Training Notebook\n","\n","**Author:** Behnam Kiani  \n","**Level:** Beginner â†’ Intermediate  \n","**Focus:** Practical computer vision with OpenCV (cv2)\n","\n","This notebook is designed as a *self-contained training course* for learning\n","image processing using **OpenCV** in Python.\n","\n","---\n","\n","## What You Will Learn\n","- Image representation & pixel mathematics\n","- Reading, displaying, and saving images\n","- Color spaces (RGB, BGR, Grayscale, HSV)\n","- Image filtering & convolution\n","- Edge detection (Sobel, Canny)\n","- Thresholding & segmentation\n","- Morphological operations\n","- Feature detection (corners)\n","- Practical mini-examples\n","\n","ðŸ“Œ **Libraries used**\n","- OpenCV (`cv2`)\n","- NumPy\n","- Matplotlib\n","\n","ðŸ”— Official OpenCV docs:  \n","https://docs.opencv.org/4.x/\n"]},{"cell_type":"markdown","id":"f14f87c3","metadata":{"id":"f14f87c3"},"source":["\n","## 1. Image Representation (Theory)\n","\n","A digital image is a **matrix** of pixel values.\n","\n","### Grayscale Image\n","$$\n","I(x,y) \\in [0,255]\n","$$\n","\n","### Color Image\n","$$\n","I(x,y) = [B, G, R]\n","$$\n","\n","OpenCV uses **BGR** format by default (not RGB).\n"]},{"cell_type":"code","execution_count":null,"id":"fe4ecaf8","metadata":{"id":"fe4ecaf8"},"outputs":[],"source":["\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","print(\"OpenCV version:\", cv2.__version__)\n"]},{"cell_type":"markdown","id":"3046cca4","metadata":{"id":"3046cca4"},"source":["\n","## 2. Reading and Displaying Images\n"]},{"cell_type":"code","execution_count":null,"id":"9a3e027f","metadata":{"id":"9a3e027f"},"outputs":[],"source":["\n","# Load image (replace path with your image)\n","image = cv2.imread('sample.jpg')\n","\n","# Check if image loaded\n","if image is None:\n","    print(\"Image not found. Please upload 'sample.jpg'.\")\n","else:\n","    print(\"Image shape:\", image.shape)\n","\n","    # Convert BGR to RGB for display\n","    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    plt.imshow(image_rgb)\n","    plt.axis('off')\n"]},{"cell_type":"markdown","id":"041e5270","metadata":{"id":"041e5270"},"source":["\n","## 3. Color Space Conversion\n","\n","### Common Color Spaces\n","- Grayscale\n","- HSV (Hue, Saturation, Value)\n","- LAB\n","\n","Conversion formula (example):\n","\\[\n","Gray = 0.299R + 0.587G + 0.114B\n","\\]\n"]},{"cell_type":"code","execution_count":null,"id":"9212a22c","metadata":{"id":"9212a22c"},"outputs":[],"source":["\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","\n","plt.figure(figsize=(10,4))\n","plt.subplot(1,2,1)\n","plt.title(\"Grayscale\")\n","plt.imshow(gray, cmap='gray')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.title(\"HSV\")\n","plt.imshow(hsv)\n","plt.axis('off')\n"]},{"cell_type":"markdown","id":"376b9ed5","metadata":{"id":"376b9ed5"},"source":["\n","## 4. Image Filtering & Convolution\n","\n","Filtering is done using a **kernel**:\n","\n","$$\n","I'(x,y) = \\sum I(x+i,y+j) \\cdot K(i,j)\n","$$\n","\n","### Common Filters\n","- Gaussian Blur (noise reduction)\n","- Median Blur (salt-and-pepper noise)\n"]},{"cell_type":"code","execution_count":null,"id":"c4713b49","metadata":{"id":"c4713b49"},"outputs":[],"source":["\n","blur = cv2.GaussianBlur(gray, (5,5), 0)\n","median = cv2.medianBlur(gray, 5)\n","\n","plt.figure(figsize=(10,4))\n","plt.subplot(1,3,1)\n","plt.title(\"Original\")\n","plt.imshow(gray, cmap='gray')\n","plt.axis('off')\n","\n","plt.subplot(1,3,2)\n","plt.title(\"Gaussian Blur\")\n","plt.imshow(blur, cmap='gray')\n","plt.axis('off')\n","\n","plt.subplot(1,3,3)\n","plt.title(\"Median Blur\")\n","plt.imshow(median, cmap='gray')\n","plt.axis('off')\n"]},{"cell_type":"markdown","id":"dce06bbf","metadata":{"id":"dce06bbf"},"source":["\n","## 5. Edge Detection\n","\n","### Sobel Operator\n","$$\n","G = \\sqrt{G_x^2 + G_y^2}\n","$$\n","\n","### Canny Edge Detector\n","Multi-stage algorithm:\n","1. Noise reduction\n","2. Gradient calculation\n","3. Non-maximum suppression\n","4. Hysteresis thresholding\n"]},{"cell_type":"code","execution_count":null,"id":"a2edf831","metadata":{"id":"a2edf831"},"outputs":[],"source":["\n","sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n","sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n","edges = cv2.Canny(gray, 100, 200)\n","\n","plt.figure(figsize=(10,4))\n","plt.subplot(1,3,1)\n","plt.title(\"Sobel X\")\n","plt.imshow(sobelx, cmap='gray')\n","plt.axis('off')\n","\n","plt.subplot(1,3,2)\n","plt.title(\"Sobel Y\")\n","plt.imshow(sobely, cmap='gray')\n","plt.axis('off')\n","\n","plt.subplot(1,3,3)\n","plt.title(\"Canny\")\n","plt.imshow(edges, cmap='gray')\n","plt.axis('off')\n"]},{"cell_type":"markdown","id":"506632a8","metadata":{"id":"506632a8"},"source":["\n","## 6. Thresholding & Segmentation\n","\n","### Binary Threshold\n","$$\n","T(x,y) =\n","\\begin{cases}\n","255 & I(x,y) > t \\\\\n","0 & \\text{otherwise}\n","\\end{cases}\n","$$\n"]},{"cell_type":"code","execution_count":null,"id":"d6912079","metadata":{"id":"d6912079"},"outputs":[],"source":["\n","_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n","adaptive = cv2.adaptiveThreshold(\n","    gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n","    cv2.THRESH_BINARY, 11, 2)\n","\n","plt.figure(figsize=(10,4))\n","plt.subplot(1,2,1)\n","plt.title(\"Global Threshold\")\n","plt.imshow(thresh, cmap='gray')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.title(\"Adaptive Threshold\")\n","plt.imshow(adaptive, cmap='gray')\n","plt.axis('off')\n"]},{"cell_type":"markdown","id":"db30eae6","metadata":{"id":"db30eae6"},"source":["\n","## 7. Morphological Operations\n","\n","Used for **shape processing**\n","- Erosion\n","- Dilation\n","- Opening\n","- Closing\n"]},{"cell_type":"code","execution_count":null,"id":"eaacb917","metadata":{"id":"eaacb917"},"outputs":[],"source":["\n","kernel = np.ones((5,5), np.uint8)\n","\n","erosion = cv2.erode(thresh, kernel, iterations=1)\n","dilation = cv2.dilate(thresh, kernel, iterations=1)\n","\n","plt.figure(figsize=(10,4))\n","plt.subplot(1,2,1)\n","plt.title(\"Erosion\")\n","plt.imshow(erosion, cmap='gray')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.title(\"Dilation\")\n","plt.imshow(dilation, cmap='gray')\n","plt.axis('off')\n"]},{"cell_type":"markdown","id":"f2a02b58","metadata":{"id":"f2a02b58"},"source":["\n","## 8. Feature Detection â€“ Corners\n","\n","### Harris Corner Detection\n","Detects regions with high intensity variation.\n"]},{"cell_type":"code","execution_count":null,"id":"9d12d9ae","metadata":{"id":"9d12d9ae"},"outputs":[],"source":["\n","gray_float = np.float32(gray)\n","corners = cv2.cornerHarris(gray_float, 2, 3, 0.04)\n","\n","image_corners = image.copy()\n","image_corners[corners > 0.01 * corners.max()] = [0,0,255]\n","\n","plt.imshow(cv2.cvtColor(image_corners, cv2.COLOR_BGR2RGB))\n","plt.title(\"Harris Corners\")\n","plt.axis('off')\n"]},{"cell_type":"markdown","id":"244f44d0","metadata":{"id":"244f44d0"},"source":["\n","## 9. Practice Ideas\n","- Face detection with Haar Cascades\n","- Object tracking\n","- Medical image preprocessing\n","- ML + OpenCV pipelines\n","\n","ðŸ”— Haar Cascades:\n","https://github.com/opencv/opencv/tree/master/data/haarcascades\n","\n","---\n","\n","## Final Notes\n","This notebook is suitable for:\n","- University courses\n","- Self-study\n","- Biomedical & engineering applications\n","\n","âœ… You now have a **solid OpenCV foundation**.\n"]}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}